\begin{abstract}
The remote procedure call (RPC) is a simple interface for executing code on a different machine. Almost none of the well known problems inherent to RPC apply on a shared memory system. Further, a shared memory system is sufficient to implement a RPC library, so that said simple interface can be more widely available.

This paper includes a minimal implementation of the proposed algorithm, with a real world implementation tested on x86-64, AMDGPU and NVPTX architectures at [[redacted-for-review]]. This can bring host capabilities to the GPU or offload code without using kernel launch APIs. The client and server both compile and run on each architecture.
\end{abstract}

\maketitle

\section{Introduction}

The remote procedure call (RPC) is a simple interface for executing code on a different machine. It's a function call, same as any other. That surface simplicity hides a variety of well known problems as characterised by Tanenbaum and Renesse\cite{TB}. Vinoksi's\cite{4557985} paper arguing to retire RPC on similar grounds is titled "Convenience over Correctness".

The observation behind this paper is that almost none of the problems inherent to RPC apply on a shared memory system, such as a heterogeneous host and graphics processing unit(s) (GPU) machine. Further, a shared memory system with limited write ordering guarantees is sufficient to implement a RPC library, so the convenience can be more widely available. This paper includes a minimal implementation of the proposed algorithm, with a real world implementation tested on x86-64, AMDGPU and NVPTX architectures at [[redacted-for-review]].


\section{Background}

Terminology is not uniform in this domain. Let client be the entity that initiates the procedure call and server be the one that does the work of the call. Process will refer to either client or server. Thread will refer to a posix thread on a cpu, to a warp on NVPTX, or to a wavefront on AMDGPU.

Remote procedure calls (RPC) are a procedure call that executes on a different process. Syntactically they are usually a local function that forwards the arguments to the remote process and retrieves the result before returning. The local functions, known as stubs, are frequently generated from declarative code as the argument forwarding process is mechanical. 

\subsection{Known problems with RPC}

This section follows those articulated by Tanenbaum and Renesse \cite{TB}, written towards the decline of industry enthusiasm for RPC as a distrubuted computation strategy. "2.3\cite{TB}" notes that RPC implies a multithreaded server but in the context of GPU compute, single threaded systems are ruled out by performance requirements anyway.

\subsubsection{When RPC doesn't fit the domain}
RPC is not a universal solution to remote computation. A calculation that can be done quicker locally, "6.2.1. Bad Assumptions\cite{TB}", or one with real time constraints "3.4 Timing Problems\cite{TB}" should be done locally. The client/server pairing doesn't map easily onto "2.5 Multicast\cite{TB}" or compute pipelines "2.1\cite{TB}", though pipelines are similar to continuation passing style which is considered in \autoref{async_call}.

\subsubsection{Partial failures}
Where RPC crosses a network it is exposed to the failure mode of the network. Multiple problems listed are consequences of defining a function that does not forward failure information, "2.2 Unexpected Messages, 2.4 The Two Army Problem, all four sections of 4 Abnormal Situations\cite{TB}".

Modern RPC frameworks accept this. Apache Thrift\cite{Thrift} reports exceptions on infrastructure failures, to be handled by the application. Google's gRPC\cite{gRPC} returns a message that includes failure information alongside the call result. However, embracing the reality of network failures changes call interfaces and introduces error handling at the call site. It no longer looks like a local function call.

A single node shared memory machine uses higher reliability communication between components than an external network, e.g. PCI Express (PCIe), a common interface for GPU to host system, includes error detection and recovery. Practically, expansion cards are less prone to unreliable connections or cables being unplugged in service than external networking. Further, an error in communication between processors within a single node can be expected to crash the processor or the entire node. Error recovery is then at the user or cluster level.

The implementation suggested here does not amend the interface to propagate errors as that removes the programmer convenience. It is thus only appropriate when failures are not partial and will need handling at the system level.

\subsubsection{ABI concerns}
"3.1 Parameter Marshalling, 3.2 Parameter Passing and 3.3 Global Variables\cite{TB}" all require some care. The implementation associated with this paper passes N uint64\_t values and expects a layer above to serialize types into those N arguments, or into shared memory to be passed by pointer. The heterogenous machine hazard is present but largely solved on existing shared memory systems by choosing compatible representations, with the edge cases handled in serialisation.

"Lack of Parallelism" is unlikely to be a problem with both server and client multi-threaded. "Lack of Streaming", where the client waits on the server, is addressed in \autoref{async_call}.

\subsection{Distributed computing}
Sun Microsystems published a note on distributed computing\cite{waldo1996note} which offers an object orientated perspective on local and distributed computation fundamentally differing. Partial failure and inability to directly pass pointers are the invasive problems for API design. The final section of the paper describes a middle ground, where the objects are guaranteed to be on the same machine, in which case indeterminacy is largely the same as for a single process. It does not distinguish a common address space from a local computation.

The thesis of this paper is essentially that shared memory systems, where said shared memory is not subject to network failure modes, are much closer to local computation than to distributed.

\section{Requirements}
The two processes require access to shared memory, implemented with sufficient write ordering that an atomic write to a flag is seen after writes to a buffer. PCIe may require the flag to be at a higher memory address than the buffer for that to be robustly true. The CUDA and HSA programming environments meet that requirement if appropriate fences are used. Atomic load and store are sufficient, compare and swap better, fetch\_and/fetch\_or ideal.

That is, given a shared memory system that allows control over the order in which writes are seen, one can implement remote procedure calls to make easier use of said shared memory system.

\section{Motivation}
\subsection{Host services}
GPU programming is primarily based on a host processor offloading tasks to a GPU. This is the case for languages CUDA, HIP, OpenCL, OpenMP, SYCL, DPC++. Exceptions are the reverse offload work of Chen et al. \cite{8606083}, source unavailable, which runs on an Intel MIC chip and uses a form of RPC to execute some tasks on the host processor and the as yet unimplemented reverse offloading feature of OpenMP 5.0\cite{openmp-5.0-spec}, section 4.1.6. 

There are tasks that the GPU cannot do without cooperation from the host, such as file and network I/O or host memory allocation. Some functions may be special cased in the compiler for some languages, e.g. printf works from CUDA GPU code (it writes to stdout at kernel exit) but fprintf is unavailable. Allocating shared memory from code running on the GPU is generally unavailable. A library implementation of RPC can be used to fill in the gaps across all language implementations, or as a means of implementing features like OpenMP 5.0 reverse offloading.

The Linux kernel syscall interface is essentially a named function call taking a fixed number of integer arguments, albeit implemented with hardware support. If the RPC function is set up to pass integers from the GPU to the host syscall interface, the GPU is granted direct access to whatever syscalls the associated host process is able to make. For example, \_\_NR\_open, \_\_NR\_write, \_\_NR\_fsync, \_\_NR\_close in sequence can be used to write to a file on the host.

\subsection{Fine grain offload}
A persistent kernel launched on the GPU can act as the server process while threads on the host (or another GPU) are the client process. The client can then run functions on the GPU through the RPC infrastructure instead of through the kernel launch API. This is likely to be slower than the vendor provided API, The kernel API may use memory allocation or waiting on asynchronous signals whereas this RPC is zero syscall and based on polling as that is the lowest common denominator.

Launching a kernel, particularly across language boundaries such as an OpenMP target region run through HIP host APIs, is subtle and error prone. Using the RPC interface instead allows implementing functions in one language and calling from another without any additional complexity. The RPC implementation itself needs to work with the native kernel API for setup and completion. Once implemented in the library however, applications can add and call functions with greater convenience.

\subsection{Process isolation}
If both client and server run as Linux processes on the same CPU, RPC on shared memory provides a zero syscall means of communicating between the two processes. A sandbox can then be implemented for a Linux client process by using seccomp to irreversibly drop access to syscalls with the still open RPC connection used to request services from the server. This may be a reasonable way to handle just in time compilation for a memory safe language implementation.

\section{interface}
There is some memory management inherent to coordinating the buffers. Expressed in C++ syntax, the interface for a given instantiation of the RPC infrastructure, is equivalent to \autoref{lst:interface}.

\begin{lstlisting}[style=c_code_style, caption={Interface}, label={lst:interface}]
void server::execute(uint64_t data[8]);
void client::call(uint64_t data[8])
{
 copy_data_to_server(data);
 server::execute(); // runs on the remote machine
 copy_data_from_server(data);
}
\end{lstlisting}

Eight uint64\_t as the argument size is suggested based on the x64 cache line size, and is enough data to invoke a Linux syscall API from the GPU, but otherwise arbitrary. An implementation such as \autoref{minimal} factors out the synchronisation and data copies, while the application implements the specific behaviour desired through callbacks.

\section{Implementation}

Implementing mutual exclusion on shared memory has known solutions, such as that attributed to Th. J. Dekker\cite{dijkstra1962over} and the later Peterson's algorithm\cite{peterson1981myths}. Those, and more complicated subsequent solutions, are not ideal for RPC which requires strictly alternating access to the shared buffer.

\subsection{One client, one server}\label{one_to_one}

The complexity is in the single client, single server case. Scaling up to multiple of each, \autoref{many}, involves multiple independent instances of the base case. This section describes the algorithm in prose, \autoref{tbl:large} as a state transition, \autoref{minimal} as executable code.

Where boolean is the smallest integer the processes can write to atomically, the client and server each have access to, in shared memory:
\begin{itemize}
\item boolean outbox, to which it may atomically write 0 or 1
\item boolean inbox, from which is may atomically read 0 or 1
\item fixed size buffer from which it may read and write N bytes
\end{itemize}

The boolean mailboxes are strictly single writer. The client outbox is the server inbox, writable by the client. The client inbox is the server outbox, writable by the server.

The state change is strictly sequential. \autoref{tbl:large} shows the changes for a complete call, proceeding down the rows. After writing to the outbox, the process waits for a change to the inbox value caused by the other process writing. Read/write access to the buffer is based on the process local mailbox values, chosen such that at most one process has access at a time.


% A function call, outside of the RPC approach, follows a sequence:
% - A call site names the function to be invoked, zero or more arguments, zero or more result values
% - The arguments are copied to somewhere that the called function knows to look for them
% - Space is allocated for returned values
% - The location to return to is written somewhere, as if it was another argument
% - Control flow jumps to that of the called function
% - The called function retrieves arguments from the location above (number)?
% - Computation occurs
% - The called function writes results to the location above (number)?
% - Control flow changes to that specified in number
% - The return values are now read from the expected location
% 
% The call site and destination need to agree on where to find and place arguments and return values. This is the 'calling convention', the details of which vary with architecture, language and sometimes with caller/callee pair within a program. Using predictable registers or stack offsets is common as it minimises the work done at runtime to determine where to find the values. Calls in tail position may be compiled as direct branches to minimise stack usage. <- todo, how much detail is useful here

% Adjusting the call process to work across machine or process boundaries involves specifying a calling convention. In this paper we assume shared memory, but no shared registers, so the place to copy arguments to when making a call is somewhere in shared memory. Returns likewise copy through shared memory. The instruction stream is not assumed to be in shared memory so that the client and server can be running concurrently or on different architectures. Control flow on the client therefore involves waiting for a response from the server before continuing, and on the server involves waiting for a request from a client. When the client does not need a result, and does not need to know the call has occurred, it can return before waiting as in \autoref{async_call}. Waiting on the server is minimised by separating work and cleanup steps which can then run on different threads.


% The calling process involves N clients and M servers forming transient pairings, during which the client thread communicates with a single dedicated server thread. That one-to-one interaction is described first, before the N-to-M is layered on top. The analogy is of mail boxes coordinating access to a shared buffer. Where boolean is the smallest integer the processes can write to atomically, the client and server each have access to, in shared memory:
% - a boolean outbox, to which it may atomically write 0 or 1
% - a boolean inbox, from which is may atomically read 0 or 1
% - a fixed size buffer from which it may read and write N uint64\_t's
% 
% The boolean mailboxes are strictly single writer. The client writes to some addresses that the server reads and vice versa. They are cross-wired, in that a given client/server pair use two mailboxes and one buffer in total. The 'outbox' on the client is the same memory as the 'inbox' on the server and vice versa. That propagates changes to the writable outbox through to the read-only inbox, subject to the properties of the underlying architecture as constrained by memory fences. Note that writes to the fixed size buffer must be ordered relative to the outbox write but need not be atomic.

Starting from all mailboxes containing zero and leaving optimisations aside, the calling sequence from the client is:
\begin{itemize}
\item Write arguments to the fixed size buffer
\item Write 1 to the outbox
\item Wait for the inbox to change to 1
\item Read results from the fixed size buffer
\item Write 0 to the outbox
\item Wait for the inbox to change to 0
\item Return
\end{itemize}

The corresponding sequence from the server is:
\begin{itemize}
\item Wait for the inbox to change to 1
\item Read arguments from the fixed size buffer
\item Do work as specified by arguments
\item Write results to the fixed size buffer
\item Write 1 to the outbox
\item Wait for the inbox to change to 0
\item Write 0 to the outbox
\item Goto start
\end{itemize}

\begin{table}
\begin{center}
\begin{tabular}{l | l l l l | l l | l}
      \multicolumn{1}{l|}{} &
      \multicolumn{2}{l}{Client} &
      \multicolumn{2}{l|}{Server} &
      \multicolumn{1}{l}{Client} &
      \multicolumn{1}{l}{Server} &
      \multicolumn{1}{l}{Buffer} \\
State            &   In  & Out  & In  & Out     &        &     & \\
\hline
Quiescent        &   0   & 0    & 0   & 0       & 0      & 0   & Client \\
Work posted      &   0   & 1    & 0   & 0       & 1      & 0   & - \\
                 &   0   & 1    & 1   & 0       & 1      & 2   & Server \\
Server working   &   0   & 1    & 1   & 0       & 1      & 2   & Server \\
Result posted    &   0   & 1    & 1   & 1       & 1      & 3   & - \\
                 &   1   & 1    & 1   & 1       & 3      & 3   & Client \\
Client working   &   1   & 1    & 1   & 1       & 3      & 3   & Client \\
Client finished  &   1   & 0    & 1   & 1       & 2      & 3   & - \\
                 &   1   & 0    & 0   & 1       & 2      & 1   & Server \\
Server finished  &   1   & 0    & 0   & 0       & 2      & 0   & - \\
                 &   0   & 0    & 0   & 0       & 0      & 0   & - \\
Client return    &   0   & 0    & 0   & 0       & 0      & 0   & Client \\

\end{tabular}
\end{center}
\caption{State transitions}
\label{tbl:large}
\end{table}

\subsection{Executable implementation}\label{minimal}
This is a minimal implementation of the one-to-one state machine, with no optimisations or cross architecture concerns, written for exposition. It will compile (as C++14) and run successfully if the listings are concatenated in order and the four external functions implemented, e.g. to do arithmetic or print to the console.

The two processes have the same fields as represented by the common base in \autoref{lst:minimal_types}. Each exposes a templated function as the application hook, here shown as calls to external C functions.

\begin{lstlisting}[style=c_code_style, caption={Types}, label={lst:minimal_types}]
header.cpp
\end{lstlisting}

The memory allocation is not owned by the client or the server (as in C++ RAII) as both client and server access the same memory. For GPU systems, the allocation is likely to be done by the host, in which case the GPU may not be able to deallocate the corresponding memory. In the [redacted] implementation one type instance, separate to client and to server, owns the allocated memory and outlives the processes. Here, \autoref{lst:minimal_main} puts the state on the free store, managed by stack objects, and spawns separate C++ threads to serve as the RPC processes. The calls variable represents minimal plumbing to handle process shutdown.

\begin{lstlisting}[style=c_code_style, caption={Main}, label={lst:minimal_main}]
main.cpp
\end{lstlisting}


The client and server (\autoref{lst:minimal_client_server}) implementations each make the handling of the four possible states explicit instead of folding the dead branches for clearer comparison to \autoref{tbl:large}.

\begin{lstlisting}[style=c_code_style, caption={Client and Server}, label={lst:minimal_client_server}]
client.cpp
server.cpp
\end{lstlisting}

\subsection{Many clients, many servers}\label{many}
The one-to-one client/server state machine requires exclusive ownership of the memory used to communicate between the two. Scaling to multiple clients or multiple servers is done with multiple one-to-one state machines, each of which runs independently and as described above, with additional locking within the process to manage mutual exclusion of the scalar state machines. No additional coordination is needed between processes.

\subsubsection{Thread scheduler}
Linux provides a completely fair scheduler by default. A thread which takes a lock and is suspended will ultimately be rescheduled, allowing the system as a whole to make progress. CUDA does not preemptively schedule threads (warps in CUDA terminology); once one starts executing it will run to completion, modulo the program ending prematurely. This also makes simple locking code possible. OpenCL provides no forward progress guarantees, and HSA makes limited ones\cite{SorensenED18}. This implementation assumes the scheduler is not fair, such that a thread which holds a lock may be descheduled and never return. Global locks are therefore unavailable. Forward progress can be ensured on AMDGPU by using at least as many distinct state machines as there can be simultaneous wavefronts on a HSA queue.

\subsubsection{Implementation limits}
This implementation assumes a limit on the number of concurrent RPC calls is specified at library initialization time. For example, it may be limited by the maximum number of concurrently executing threads the hardware can support. It then allocates that many instances of the communication state up front, as a contiguous array, to avoid the complexity of reallocating concurrently accessed structures. On contemporary AMDGPU hardware it implies ~8MiB of host memory reserved per instance, with some overhead from cache invalidation as a result. This may be revised in future.

\subsubsection{Mutual exclusion}
Each one-to-one state machine can be used by a single client and a single server at a time. Mutual exclusion, combined with the implementation choice of a fixed size array of said state machines, means picking an index which is otherwise unused.

The additional invariant relative to \autoref{one_to_one} is that a given outbox can now only be written to while the corresponding lock is held. That is sufficient to serialize operations on the individual state machines.

The lock acquire can be very cheap for systems where the process is comprised of N threads each of which can be dedicated to a single index. For example, if the array is as wide as the maximum number of warps on an NVPTX machine, compiler intrinsics can uniquely identify that warp, and use that identifier as an index. It is also cheap if the process contains a single thread, which may be the case for a CPU server implementation, or if a feature of the surrounding infrastructure for thread management provides an ID in [0, number-threads).

In other cases, a slot can be found dynamically using a bitmap of length equal to the maximum number of calls as an array of mutual exclusion locks. This lock array is local to the process so atomic compare and swap to set a bit at index I is taking a lock at I, which can be released by fetch\_and with a mask. 
Provided locks or a priori knowledge ensures each one-to-one state machine is only in use by one pair of processes at a time, correctness of the whole system follows from correctness of a single pair. The concept of holding a lock on an index is useful for reasoning about optimisations, whether the lock is a bit set in a bitmap or implicit.

\subsection{Algorithm adaption for process locking}
Both processes proceed by selecting a state machine that they can make progress on, claiming the lock for it, and then checking whether there is still work to be done. 
Multiple client algorithm:
\begin{itemize}
\item find an index that is outbox clear, inbox clear
\item acquire a lock on that index
\item if it is no longer outbox clear, inbox clear, release lock and return
\item proceed as in the one-to-one case
\item release the lock
\end{itemize}
Multiple server algorithm:
\begin{itemize}
\item find an index that is outbox clear, inbox set
\item acquire a lock on that index
\item if it is no longer outbox clear, inbox set, release lock and return
\item proceed as in the one-to-one-case
\item release the lock
\end{itemize}

\section{Optimisations}
\subsection{Asynchronous call}\label{async_call}
Some function calls have no return value, e.g. for memory deallocation. The state machine described so far requires the client to detect that the call has succeeded and set the client outbox to 0, ultimately freeing up the slot for reuse. This can be relaxed, permitting the client to return immediately after posting work by setting the outbox to 1, provided some other client call can recognise the case and clean up.

The case of a previous asynchronous call is detectable when the outbox and inbox set, indicating a result has been received, however the corresponding lock is not set (or is implicit), so no client is waiting for it. The server code does not need to be changed.
A call may be split into an asynchronous one that triggers some work and a later synchronous call that retrieves the result, or multiple asynchronous calls to query whether the result is available yet. This diverges from the simple RPC model of an invisible local call though, requiring application collaboration, so is not explored further in this paper.

\subsection{Bit packing}
The previous assumed a boolean is stored in the smallest integer that the process can write atomically. If the process can write with fetch\_or, or atomic compare and swap, the mailbox entries can be packed into fewer machine words that are written atomically. Fetch\_or is ideal but not provided as part of the base PCIe specification. Atomic compare and swap is usually susceptible to the ABA problem, but in this case the bit corresponding to the current slot can only be changed by the thread holding the corresponding lock. The compare and swap can never spuriously succeed as no other thread is trying to set the same value.

\subsection{Batching outbox}
The processes access to shared memory may be high latency and based on atomic compare and swap (CAS), e.g. across PCIe. The failure case is then expensive, where a given thread lost the race and must try again. For a 64 bit compare and swap, 64 outbox updates can be passed with a single successful compare. This can be done by maintaining a process local bitmap for the outbox which is updated with fetch\_and/fetch\_or to change the index currently locked. After updating the process local bitmap, enter a loop trying to update the shared memory outbox. The cases are then:
\begin{itemize}
\item CAS success, have written to the outbox, return
\item CAS failed, indexed bit is different to the local outbox, try again
\item CAS failed, indexed bit is the same as the local outbox, return
\end{itemize}
That amounts to each competing thread trying to update multiple values and returning as soon as it, or one of the other threads, succeeds in propagating the locked value.

\subsection{Exceeding fixed buffer size}
Shared memory RPC can handle larger arguments by allocating memory and passing a pointer. An alternative is a variant on the asynchronous call, where the client takes a lock and issues multiple call/return sequences before dropping the lock. The server can combine the buffers at that index. This is used in a printf implementation where the data passed can exceed any fixed size buffer but an allocation round trip introduces failure modes. Notably, because the lock is an integer index, it is also usable as a unique identifier during the call which help the server reassemble associated buffers. This remains opaque to the call site.

\section{Limitations and future work}
\subsection{Syntax}
Development efforts have been focused on providing a correct and performant means of calling a function on N integers. Ease of use requires a layer on top of this to handle implicit serialization of types and passing function pointers.

\subsection{Combinatorial testing}
Verifying that the client and server process both compile on various architectures, as various languages, can be done in linear time on a single machine with a cross compiler. Verifying that each pair executes successfully requires further infrastructure, such as a unit test framework and thread pool definition that can execute on each architecture, to reach the point where a single client/server application can be compiled repeatedly and run under various different environments.

\subsection{Further architectures}\label{further}
The implementation is presently tested on pre-Volta NVPTX, where the remote call is made on a per-warp basis. Extending to Volta means passing a thread mask down the call stack and allowing each thread in the warp to initiate the remote call, closer to the x86-64 model. Extending to a PowerPC host may uncover little endian assumptions. Intel or ARM GPUs will require additional implementations of some platform specific code.

\subsection{Performance}
Different pairs of architecture, and different communication fabrics benefit from different optimisations. For example, batching may be worthwhile across high latency PCIe and a net loss on a faster connection. Determining the optimal set of variations for different systems will follow from benchmarks that can run across various different systems, so follows on from \autoref{further}. This should all be variations in derived template parameters, unobservable to applications that are already using the unspecialized library.

\section{Conclusion}
Remote procedure calls are a simple interface if and only if there are no network induced failure modes. This is the case on a single shared memory GPU node. The synchronisation required can be implemented on shared memory systems with two atomic booleans per RPC state instance with single writer semantics and a fixed size shared buffer for argument and return passing.

A mechanism built on shared memory such as this, or waiting for vendor support, enables file I/O and similar from GPU code. Mmap of a file into shared memory from the GPU is a particularly good fit.

Once coupled with a code generation scheme such as \cite{Thrift} or similar, a state machine such as this provides a convenient means of executing functions on a different processor to the caller. 
